{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baada02f",
   "metadata": {},
   "source": [
    "# Finetuning using LoRA for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1217374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importting necessary library\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification, DataCollatorWithPadding,TrainingArguments,TrainerState,Trainer\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2188da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the base model distilbert-base-uncased\n",
    "model_checkpoint = 'distilbert-base-uncased'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08825ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the labels for mapping\n",
    "id2label = {0:\"Negative\", 1:\"Possitive\"}\n",
    "label2id = {\"Negative\":0, \"Possitive\":1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47c6450f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "model_checkpoint,num_labels=2,id2label=id2label,label2id=label2id)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f336214a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the dataset \n",
    "dataset = load_dataset(\"shawhin/imdb-truncated\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c0130ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1917427dba86469fb2f7c3274da6862c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42cdd3c3da944e26a9c7fa999003720c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a4b935689542d48e7ea443f980ba52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint,add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23c19952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(inputs):\n",
    "    text = inputs['text']\n",
    "    \n",
    "    tokenizer.truncation_side=\"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "    text,\n",
    "    return_tensors=\"np\",\n",
    "    truncation=True,\n",
    "    max_length=512)\n",
    "    \n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a521eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If none exists then add pad token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token':'[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b149ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d702c7eac541378dc5b26a7948b670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb26e87439dd4e7b9119be5b3075d020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_function,batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdd5afba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorWithPadding(tokenizer=DistilBertTokenizerFast(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}, padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data collatorto dinamically pad inputs in each batch during training \\\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7badcf9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jan 18 15:08:51 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 566.14                 Driver Version: 566.14         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650 Ti   WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   52C    P8              2W /   50W |      75MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      2548    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A      2588    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe      N/A      |\n",
      "|    0   N/A  N/A      6548    C+G   ...aam7r\\AcrobatNotificationClient.exe      N/A      |\n",
      "|    0   N/A  N/A      9992    C+G   C:\\Windows\\System32\\ShellHost.exe           N/A      |\n",
      "|    0   N/A  N/A     11160    C+G   ...282.0_x64__dt26b99r8h8gj\\RtkUWP.exe      N/A      |\n",
      "|    0   N/A  N/A     12760    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     12836    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     14940    C+G   ...__wafk5atnkzcwy\\mcafee-security.exe      N/A      |\n",
      "|    0   N/A  N/A     16444    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     16836    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     17204    C+G   ...n\\131.0.2903.146\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     18840    C+G   ...3.0_x64__cv1g1gvanyjgm\\WhatsApp.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a16f2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc1e5769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(p):\n",
    "    predictions,labels=p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\":accuracy.compute(predictions=predictions, references=labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5156a511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of inputs \n",
    "sentiment_examples = [ \"Oh, great! Another meeting. Just what I needed.\",\n",
    "    \"The movie was amazing, but the ending was terrible.\",\n",
    "    \"I’m not sure if I like it or not.\",\n",
    "    \"I just love waiting in long lines for hours!\",\n",
    "    \"If this app worked better, I’d love it.\",\n",
    "    \"It’s not the best thing I’ve ever seen, but I guess it’s okay.\",\n",
    "    \"This is the worst movie ever made! It’s unbearable!\",\n",
    "    \"I’m so excited to be stuck in traffic for an hour!\",\n",
    "    \"The food was great, but the service was terrible.\",\n",
    "    \"This is hands down the best pizza in the world.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d74d075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions of the untrained models\n",
      "*----------------------------------*\n",
      "Oh, great! Another meeting. Just what I needed. = Negative\n",
      "The movie was amazing, but the ending was terrible. = Negative\n",
      "I’m not sure if I like it or not. = Negative\n",
      "I just love waiting in long lines for hours! = Possitive\n",
      "If this app worked better, I’d love it. = Negative\n",
      "It’s not the best thing I’ve ever seen, but I guess it’s okay. = Negative\n",
      "This is the worst movie ever made! It’s unbearable! = Possitive\n",
      "I’m so excited to be stuck in traffic for an hour! = Negative\n",
      "The food was great, but the service was terrible. = Negative\n",
      "This is hands down the best pizza in the world. = Negative\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions of the untrained models\")\n",
    "print(\"*----------------------------------*\")\n",
    "for sentiment in sentiment_examples:\n",
    "    inputs = tokenizer.encode(sentiment,return_tensors=\"pt\")\n",
    "    logits = model(inputs).logits\n",
    "    predictions = torch.argmax(logits)\n",
    "    \n",
    "    print(sentiment+\" = \" + id2label[predictions.tolist()])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f329fd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now finetuning the base model using peft\n",
    "peft_config = LoraConfig(task_type=\"SEQ_CLS\",\n",
    "                        r = 4,\n",
    "                        lora_alpha=32,\n",
    "                        lora_dropout = 0.01,\n",
    "                        target_modules=['q_lin']\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53aa03b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 628,994 || all params: 67,584,004 || trainable%: 0.9307\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model,peft_config=peft_config)\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39d35887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining hypterparameters\n",
    "lr = 0.001\n",
    "batch_size = 4\n",
    "num_epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d25bb834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6f82556",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define training arguments\n",
    "training_args = TrainingArguments(\n",
    "output_dir = model_checkpoint+\"-lora-text-classification\",\n",
    "learning_rate=lr,\n",
    "per_device_eval_batch_size=batch_size,\n",
    "per_device_train_batch_size=batch_size,\n",
    "num_train_epochs=num_epochs,\n",
    "weight_decay=0.01,\n",
    "evaluation_strategy=\"epoch\",\n",
    "save_strategy=\"epoch\",\n",
    "load_best_model_at_end=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba9a3561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): DistilBertForSequenceClassification(\n",
       "      (distilbert): DistilBertModel(\n",
       "        (embeddings): Embeddings(\n",
       "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (transformer): Transformer(\n",
       "          (layer): ModuleList(\n",
       "            (0-5): 6 x TransformerBlock(\n",
       "              (attention): MultiHeadSelfAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=4, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=4, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (activation): GELUActivation()\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pre_classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=2, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0bc3a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "model=model,\n",
    "args=training_args,\n",
    "train_dataset=tokenized_dataset['train'],\n",
    "eval_dataset=tokenized_dataset['validation'],\n",
    "tokenizer= tokenizer,\n",
    "data_collator=data_collator,\n",
    "compute_metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3695481e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2500/2500 14:50, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.440025</td>\n",
       "      <td>{'accuracy': 0.881}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.311600</td>\n",
       "      <td>0.558453</td>\n",
       "      <td>{'accuracy': 0.884}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.311600</td>\n",
       "      <td>0.655431</td>\n",
       "      <td>{'accuracy': 0.886}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.121900</td>\n",
       "      <td>0.836520</td>\n",
       "      <td>{'accuracy': 0.886}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.121900</td>\n",
       "      <td>0.933128</td>\n",
       "      <td>{'accuracy': 0.876}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>1.073383</td>\n",
       "      <td>{'accuracy': 0.88}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>1.066068</td>\n",
       "      <td>{'accuracy': 0.888}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>1.097809</td>\n",
       "      <td>{'accuracy': 0.881}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>1.049472</td>\n",
       "      <td>{'accuracy': 0.887}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>1.051321</td>\n",
       "      <td>{'accuracy': 0.884}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.881}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.884}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.886}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.886}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.876}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.88}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.888}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.881}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.887}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.884}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2500, training_loss=0.09780876092910766, metrics={'train_runtime': 890.4965, 'train_samples_per_second': 11.23, 'train_steps_per_second': 2.807, 'total_flos': 1221911383617024.0, 'train_loss': 0.09780876092910766, 'epoch': 10.0})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb83fb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Prediciton with trained model\n",
      "Oh, great! Another meeting. Just what I needed. = Possitive\n",
      "The movie was amazing, but the ending was terrible. = Negative\n",
      "I’m not sure if I like it or not. = Possitive\n",
      "I just love waiting in long lines for hours! = Possitive\n",
      "If this app worked better, I’d love it. = Possitive\n",
      "It’s not the best thing I’ve ever seen, but I guess it’s okay. = Possitive\n",
      "This is the worst movie ever made! It’s unbearable! = Negative\n",
      "I’m so excited to be stuck in traffic for an hour! = Possitive\n",
      "The food was great, but the service was terrible. = Negative\n",
      "This is hands down the best pizza in the world. = Possitive\n"
     ]
    }
   ],
   "source": [
    "#Now validaiton on the text lists\n",
    "print(\" Prediciton with trained model\")\n",
    "\n",
    "sentiment_example = [\"The movie was absolutely amazing, with incredible performances from the cast!\",\n",
    "    \"I couldn’t stand the movie, it was so boring and predictable.\",\n",
    "    \"The visuals were stunning, but the storyline was a bit weak.\",\n",
    "    \"A fun movie for the whole family, I really enjoyed it!\",\n",
    "    \"I didn’t enjoy the movie at all, I thought it was a waste of time.\",\n",
    "    \"The acting was decent, but the plot didn’t make much sense.\",\n",
    "    \"It’s a classic! This movie will always be one of my favorites.\",\n",
    "    \"I expected more from this film, it didn’t live up to the hype.\",\n",
    "    \"The movie was fine, nothing extraordinary, but I didn’t hate it.\",\n",
    "    \"What a disappointment! I was really looking forward to it, but it was terrible.\"]\n",
    "\n",
    "for sentiment in sentiment_example:\n",
    "    inputs = tokenizer.encode(sentiment, return_tensors=\"pt\").to(device)\n",
    "    logits = model(inputs).logits\n",
    "    predictions = torch.max(logits,1).indices\n",
    "    print(sentiment+\" = \"+id2label[predictions.tolist()[0]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1683ed15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
